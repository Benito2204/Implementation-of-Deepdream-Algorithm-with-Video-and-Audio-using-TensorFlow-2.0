pip install tensorflow-gpu==2.2.0
tf.__version__

PART 1- DEFINE DEEPDREAM MODEL

IMPORT LIBRARIES
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import PIL.Image
import cv2
import os
import random

IMPORT INCEPTIONV3 MODEL
base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')
base_model.summary()

PICK THE LAYERS AND FEED THEM INTO THE DEEPDREAM MODEL
# Maximize the activations of these layers
# names = ['mixed8', 'mixed9']
# names = ['mixed3', 'mixed5', 'mixed8', 'mixed9']
names = ['mixed3', 'mixed5', 'mixed7']
# names = ['mixed5']
layers = [base_model.get_layer(name).output for name in names]
# Create the feature extraction model
deepdream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)

IMPORT THE FIRST IMAGE (MARS)
from google.colab import files
uploaded = files.upload()
from PIL import Image # Python Image Library is a library that adds support for opening, manipulating, and saving many different image file formats
# This helper function loads an image and returns it as a numpy array of floating points
def load_image(filename):
    image = PIL.Image.open(filename)
    return np.float32(image)
# Open the first image
img_1= Image.open("mars.jpg")
img_1

IMPORT THE SECOND IMAGE (EIFFEL TOWER)
from google.colab import files
uploaded = files.upload()
# Open the second image
img_2= Image.open("eiffel.jpg")
img_2

BLEND THE TWO IMAGES AND SAVE IT IN THE DRIVE
# Blend the two images
image= Image.blend(img_1, img_2, 0.5) #alpha --> The interpolation alpha factor. If alpha is 0.0, a copy of the first image is returned.
# If alpha is 1.0, a copy of the second image is returned. There are no restrictions on the alpha value.
# If necessary, the result is clipped to fit into the allowed output range.
# Display the blended image
image
# Save the blended image as the starting image (img_0,....)
image.save("img_0.jpg")

PREPROCESS THE BLENDED IMAGE
image= tf.keras.preprocessing.image.load_img("img_0.jpg")
plt.imshow(image)
np.shape(image)
# Normalize the image
image = np.array(image)/255.0
image.shape
image.max()
image.min()

RUN THE PRE-TRAINED MODEL AND EXPLORE ACTIVATIONS
image = tf.keras.preprocessing.image.img_to_array(image)
image.shape
image = tf.Variable(tf.keras.applications.inception_v3.preprocess_input(image))
image = tf.expand_dims(image, axis = 0)
np.shape(image)
# Run the model by feeding in an input image and take a look at the activations
activations = deepdream_model(image)
activations
len(activations)
print(np.shape(activations))

DEEPDREAM LOSS CALCULATION
The objective of this function is to select a layer and attempt at maximizing the loss which is the activations generated by the layer of interest
def calc_loss(image, model):
# Function used for loss calculations
# It works by feedforwarding the input image through the network and generate activations
# Then obtain the average and sum of those outputs

  img_batch = tf.expand_dims(image, axis=0) # Convert into batch format
  layer_activations = model(img_batch) # Run the model
  print('ACTIVATION VALUES (LAYER OUTPUT) =\n', layer_activations)
  # print('ACTIVATION SHAPE =\n', np.shape(layer_activations))

  losses = [] # accumulator to hold all the losses
  for act in layer_activations:
    loss = tf.math.reduce_mean(act) # calculate mean of each activation 
    losses.append(loss)
  
  print('LOSSES (FROM MULTIPLE ACTIVATION LAYERS) = ', losses)
  print('LOSSES SHAPE (FROM MULTIPLE ACTIVATION LAYERS) = ', np.shape(losses))
  print('SUM OF ALL LOSSES (FROM ALL SELECTED LAYERS)= ', tf.reduce_sum(losses))

  return  tf.reduce_sum(losses) # Calculate sum 
  
#Let's test the function
Sample_Image= tf.keras.preprocessing.image.load_img("img_0.jpg")
Sample_Image = np.array(Sample_Image)/255.0
Sample_Image = tf.keras.preprocessing.image.img_to_array(Sample_Image)
Sample_Image = tf.Variable(tf.keras.applications.inception_v3.preprocess_input(Sample_Image))
loss = calc_loss(Sample_Image, deepdream_model)
loss # Sum up the losses from both activations

GRADIENT ASCENT CALCULATIONS
In this step, we will rely on the loss that has been calculated in the previous step and calculate the gradient with respect to the given input image and then add it to the input image (blended image). Doing so iteratively will result in feeding images that continuously and increasingly excite the neurons and generate more dreamy like images

def deepdream(model, image, step_size):
    with tf.GradientTape() as tape:
      # This needs gradients relative to `img`
      # `GradientTape` only watches `tf.Variable`s by default
      tape.watch(image)
      loss = calc_loss(image, model) # call the function that calculate the loss 

    # Calculate the gradient of the loss with respect to the pixels of the input image.
    # The syntax is as follows: dy_dx = g.gradient(y, x) 
    gradients = tape.gradient(loss, image)

    print('GRADIENTS =\n', gradients)
    print('GRADIENTS SHAPE =\n', np.shape(gradients))

    # tf.math.reduce_std computes the standard deviation of elements across dimensions of a tensor
    gradients /= tf.math.reduce_std(gradients)  

    # In gradient ascent, the "loss" is maximized so that the input image increasingly "excites" the layers.
    # You can update the image by directly adding the gradients (because they're the same shape!)
    image = image + gradients * step_size
    image = tf.clip_by_value(image, -1, 1)

    return loss, image
    
def run_deep_dream_simple(model, image, steps=100, step_size=0.01):
  # Convert from uint8 to the range expected by the model.
  image = tf.keras.applications.inception_v3.preprocess_input(image)

  for step in range(steps):
    loss, image = deepdream(model, image, step_size)
    
    if step % 100 == 0:
      plt.figure(figsize=(12,12))
      plt.imshow(deprocess(image))
      plt.show()
      print ("Step {}, loss {}".format(step, loss))

  # clear_output(wait=True)
  plt.figure(figsize=(12,12))
  plt.imshow(deprocess(image))
  plt.show()

  return deprocess(image)

# Noramlize the image

def deprocess(image):
  image = 255*(image + 1.0)/2.0
  return tf.cast(image, tf.uint8)
  
Part 2- Create frames of the deep dream

from google.colab import drive
drive.mount('/content/drive')

# Name of the folder
dream_name= 'mars_eiffel'

# Blended image dimension
x_size= 910 # larger the image longer is going to take to fetch the frames 
y_size= 605

# Randomly check the result of the frame
reated_count= 0
max_count= 200

for i in range(0, 200):
    # Get into the dream directory and looks for the number of images and then figure out what is the latest image. Hence this 
    # image we are going to start with and let it dream on and on
    
    if os.path.isfile('dream_1/{}/img_{}.jpg'.format(dream_name, i+1)):
        print("{} present already, continue fetching the frames...".format(i+1))
        
    else:
        # Call the load image funtion
        img_result = load_image(r'/content/drive/My Drive/dream_1/{}/img_{}.jpg'.format(dream_name, i))
                                                                          
        # Zoom the image 
        
        x_zoom = 2 # this gives how quick the zoom is 
        y_zoom = 1
        
        # Chop off the edges of the image and resize the image back to the original shape. This gives the visual changes of a zoom
        
        img_result = img_result[0+x_zoom : y_size-y_zoom, 0+y_zoom : x_size-x_zoom]
        img_result = cv2.resize(img_result, (x_size, y_size))
        
        # Adjust the RGB value of the image
        
        img_result[:, :, 0] += 2  # red
        img_result[:, :, 1] += 2  # green
        img_result[:, :, 2] += 2  # blue
        
        # Deep dream model  
        img_result = run_deep_dream_simple(model= deepdream_model, image= img_result, steps= 500, step_size= 0.001)
        
        # Clip the image, convert the datatype of the array, and then convert to an actual image. 
        img_result = np.clip(img_result, 0.0, 255.0)
        img_result = img_result.astype(np.uint8)
        result = PIL.Image.fromarray(img_result, mode='RGB')
        
        # Save all the frames in the dream location
        result.save(r'/content/drive/My Drive/dream_1/{}/img_{}.jpg'.format(dream_name, i+1))
        
        created_count += 1
        if created_count > max_count:
            break
            
Part 3- Create a video from all the frames
Download all the frames (mars_eiffel folder) from the google drive and upload in the Files section
from google.colab import files
uploaded = files.upload()

# Unzip the folder

from zipfile import ZipFile
file_name = "mars_eiffel.zip"

with ZipFile(file_name, 'r') as zip:
  zip.extractall()
  print('Done')
  
# Path of all the frames
dream_path = "mars_eiffel"

# Define the codec and create VideoWriter object 

fourcc = cv2.VideoWriter_fourcc(*'XVID') # FourCC is a 4-byte code used to specify the video codec

out = cv2.VideoWriter('video.avi', fourcc, 5.0, (910, 605)) # Specify the fourCC, frames per second (fps),
                                                                            # and frame size
# The frames per second value is depends on few important things
# 1. The number of frames we have created. Less number of frames brings small fps
# 2. The larger the image the bigger the fps value. For example, 1080 pixel image can bring 60 fps 

for i in range(9999999999999):
    
    # Get into the dream directory and looks for the number of images and then figure out what is the latest image. Hence with 
    # this image we are going to start with and let it dream on and on
    if os.path.isfile('drive/My Drive/dream_1/mars_eiffel/img_{}.jpg'.format(i+1)):
        pass
    # Figure out how long the dream is 
    else:
        dream_length = i
        break
        
 # Write this frame out to our file for evry frame we have

for i in range(dream_length):
    
    # Build the frames of cv2.VideoWriter
    img_path = os.path.join(dream_path, 'img_{}.jpg'.format(i)) # join the dream path
    
    print(img_path) # print the image path 
    
    frame = cv2.imread(img_path)
    out.write(frame)

out.release()

Part 4- Insert audio to the deep dream video
# 5 frames per second

import moviepy.editor as mp
video= mp.VideoFileClip(r'/content/drive/My Drive/dream_1/mars_eiffel.avi')
video.write_videofile("output.mp4", audio= r'/content/drive/My Drive/dream_1/audio.mp3')
